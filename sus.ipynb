{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-19T17:26:46.166289Z",
     "start_time": "2025-11-19T17:26:16.970688Z"
    }
   },
   "source": [
    "# ============================================================================\n",
    "# LIEBHERR HACKATHON 2025 - VERBESSERTES MODELL\n",
    "# ============================================================================\n",
    "# Dieses Notebook enth√§lt mehrere Verbesserungen:\n",
    "# 1. Ber√ºcksichtigung der bisherigen Auftrags-Historie\n",
    "# 2. Feature Engineering (Fortschritt, Verz√∂gerungen, etc.)\n",
    "# 3. Mehrere Modell-Ans√§tze (Baseline, verbessert, ML)\n",
    "# 4. Bessere Vorhersagequalit√§t\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LIEBHERR HACKATHON 2025 - VERBESSERTES MODELL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 1: DATEN LADEN UND VORBEREITEN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 1: DATEN LADEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Daten laden\n",
    "df_history = pd.read_csv('df_history_clean.csv')\n",
    "df_eval_public = pd.read_csv('df_eval_public_2025-11-03.csv')\n",
    "df_eval_private = pd.read_csv('df_eval_private_2025-11-03.csv')\n",
    "df_ids = pd.read_csv('df_IDs_for_eval_2025-11-03.csv')\n",
    "\n",
    "print(f\"‚úì df_history geladen: {len(df_history):,} Zeilen\")\n",
    "print(f\"‚úì df_eval_public geladen: {len(df_eval_public):,} Zeilen\")\n",
    "print(f\"‚úì df_eval_private geladen: {len(df_eval_private):,} Zeilen\")\n",
    "print(f\"‚úì df_ids geladen: {len(df_ids):,} IDs\")\n",
    "\n",
    "# Kombiniere eval Dateien\n",
    "df_eval = pd.concat([df_eval_public, df_eval_private], ignore_index=True)\n",
    "print(f\"‚úì df_eval kombiniert: {len(df_eval):,} Zeilen\")\n",
    "\n",
    "# Datumsspalten konvertieren\n",
    "date_cols_history = ['Auftragseingang', 'Auftragsende_SOLL', 'AFO_Start_SOLL',\n",
    "                     'AFO_Ende_SOLL', 'AFO_Start_IST', 'AFO_Ende_IST', 'Auftragsende_IST']\n",
    "date_cols_eval = ['Auftragseingang', 'Auftragsende_SOLL', 'AFO_Start_SOLL',\n",
    "                  'AFO_Ende_SOLL', 'AFO_Start_IST']\n",
    "\n",
    "for col in date_cols_history:\n",
    "    if col in df_history.columns:\n",
    "        df_history[col] = pd.to_datetime(df_history[col], errors='coerce')\n",
    "\n",
    "for col in date_cols_eval:\n",
    "    if col in df_eval.columns:\n",
    "        df_eval[col] = pd.to_datetime(df_eval[col], errors='coerce')\n",
    "\n",
    "print(\"‚úì Datumsspalten konvertiert\")\n",
    "\n",
    "# Stichtag definieren\n",
    "STICHTAG = pd.Timestamp('2024-03-01 14:30:00')\n",
    "print(f\"\\n‚úì Stichtag: {STICHTAG}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 2: HILFSFUNKTIONEN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 2: HILFSFUNKTIONEN DEFINIEREN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def add_business_hours(start_dt, hours):\n",
    "    \"\"\"\n",
    "    Addiert Arbeitsstunden zu einem Startdatum.\n",
    "    Arbeitszeit: Mo-Fr, 07:00-15:00 (8 Stunden/Tag)\n",
    "    Feiertage werden gearbeitet.\n",
    "    \"\"\"\n",
    "    if pd.isna(start_dt) or hours <= 0:\n",
    "        return start_dt\n",
    "\n",
    "    # Anzahl volle Arbeitstage\n",
    "    full_days = int(hours // 8)\n",
    "    remaining_hours = hours % 8\n",
    "\n",
    "    # Normalisiere auf 07:00 des aktuellen Tages\n",
    "    current = pd.Timestamp(start_dt.date()) + pd.Timedelta(hours=7)\n",
    "\n",
    "    # Wenn Startzeit nach 07:00 ist, ber√ºcksichtige das\n",
    "    if start_dt.hour >= 7 and start_dt.hour < 15:\n",
    "        current = start_dt\n",
    "    elif start_dt.hour >= 15:\n",
    "        # Nach Feierabend -> n√§chster Tag 07:00\n",
    "        current = pd.Timestamp(start_dt.date()) + pd.Timedelta(days=1, hours=7)\n",
    "        # Wenn das ein Wochenende ist, springe zu Montag\n",
    "        while current.weekday() >= 5:\n",
    "            current += pd.Timedelta(days=1)\n",
    "\n",
    "    # Addiere volle Arbeitstage\n",
    "    days_added = 0\n",
    "    while days_added < full_days:\n",
    "        current += pd.Timedelta(days=1)\n",
    "        if current.weekday() < 5:  # Mo-Fr\n",
    "            days_added += 1\n",
    "\n",
    "    # Addiere verbleibende Stunden\n",
    "    if remaining_hours > 0:\n",
    "        # Pr√ºfe ob wir noch am selben Tag bleiben\n",
    "        end_time = current + pd.Timedelta(hours=remaining_hours)\n",
    "        if end_time.hour > 15 or (end_time.hour == 15 and end_time.minute > 0):\n",
    "            # √úberschreitet Feierabend -> n√§chster Arbeitstag\n",
    "            overflow = (end_time - current.replace(hour=15, minute=0, second=0)).total_seconds() / 3600\n",
    "            current = current.replace(hour=15, minute=0, second=0)\n",
    "            # N√§chster Tag\n",
    "            current += pd.Timedelta(days=1, hours=7)\n",
    "            while current.weekday() >= 5:\n",
    "                current += pd.Timedelta(days=1)\n",
    "            current += pd.Timedelta(hours=overflow)\n",
    "        else:\n",
    "            current = end_time\n",
    "\n",
    "    return current\n",
    "\n",
    "\n",
    "def calculate_business_hours_between(start_dt, end_dt):\n",
    "    \"\"\"\n",
    "    Berechnet Arbeitsstunden zwischen zwei Zeitpunkten.\n",
    "    Mo-Fr, 07:00-15:00, Feiertage werden gearbeitet.\n",
    "    \"\"\"\n",
    "    if pd.isna(start_dt) or pd.isna(end_dt):\n",
    "        return 0\n",
    "\n",
    "    if end_dt <= start_dt:\n",
    "        return 0\n",
    "\n",
    "    # Vereinfachte Berechnung: Z√§hle Werktage * 8h\n",
    "    start_date = start_dt.date()\n",
    "    end_date = end_dt.date()\n",
    "\n",
    "    # Nutze numpy f√ºr effiziente Berechnung\n",
    "    business_days = np.busday_count(start_date, end_date)\n",
    "\n",
    "    return business_days * 8.0\n",
    "\n",
    "\n",
    "print(\"‚úì Hilfsfunktionen definiert\")\n",
    "print(\"  - add_business_hours(): Addiert Arbeitsstunden zu einem Datum\")\n",
    "print(\"  - calculate_business_hours_between(): Berechnet Arbeitsstunden zwischen zwei Daten\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 3: LERN-PHASE - STATISTIKEN AUS HISTORY EXTRAHIEREN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 3: LEARNING - EXTRAHIERE STATISTIKEN AUS HISTORY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 3.1: Standardarbeitsplan pro Bauteil\n",
    "print(\"\\n3.1 Standardarbeitsplan pro Bauteil extrahieren...\")\n",
    "\n",
    "# Finde f√ºr jedes Bauteil die typische Anzahl AFOs\n",
    "standard_afo_plan = df_history.groupby(['BauteilID', 'AuftragsID'])['Arbeitsschritt'].max().groupby('BauteilID').agg(['median', 'mean', 'max'])\n",
    "standard_afo_plan.columns = ['Median_AFOs', 'Mean_AFOs', 'Max_AFOs']\n",
    "print(\"\\nStandardarbeitsplan (Anzahl AFOs):\")\n",
    "print(standard_afo_plan)\n",
    "\n",
    "# Dictionary f√ºr schnellen Zugriff\n",
    "standard_afo_count = standard_afo_plan['Median_AFOs'].to_dict()\n",
    "\n",
    "\n",
    "# 3.2: Durchschnittliche Dauer pro Bauteil\n",
    "print(\"\\n3.2 Berechne durchschnittliche Gesamtdauer pro Bauteil...\")\n",
    "\n",
    "# Filtere komplette Auftr√§ge (mit Auftragsende_IST)\n",
    "complete_orders = df_history[df_history['Auftragsende_IST'].notna()].copy()\n",
    "\n",
    "# Berechne Dauer von erstem Start bis letztem Ende\n",
    "order_durations = complete_orders.groupby('AuftragsID').agg({\n",
    "    'BauteilID': 'first',\n",
    "    'Bauteilbezeichnung': 'first',\n",
    "    'AFO_Start_IST': 'min',\n",
    "    'Auftragsende_IST': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Berechne Arbeitsstunden\n",
    "order_durations['Duration_Hours'] = order_durations.apply(\n",
    "    lambda row: calculate_business_hours_between(row['AFO_Start_IST'], row['Auftragsende_IST']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Entferne negative oder zu gro√üe Dauern (Datenqualit√§t)\n",
    "order_durations = order_durations[\n",
    "    (order_durations['Duration_Hours'] > 0) &\n",
    "    (order_durations['Duration_Hours'] < 10000)\n",
    "]\n",
    "\n",
    "# Statistiken pro Bauteil\n",
    "duration_stats = order_durations.groupby(['BauteilID', 'Bauteilbezeichnung'])['Duration_Hours'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Median_Hours', 'median'),\n",
    "    ('Mean_Hours', 'mean'),\n",
    "    ('Std_Hours', 'std'),\n",
    "    ('Q25_Hours', lambda x: x.quantile(0.25)),\n",
    "    ('Q75_Hours', lambda x: x.quantile(0.75))\n",
    "]).reset_index()\n",
    "\n",
    "print(\"\\nDauer-Statistiken pro Bauteil:\")\n",
    "for _, row in duration_stats.iterrows():\n",
    "    print(f\"\\n{row['Bauteilbezeichnung']} (BauteilID={int(row['BauteilID'])}):\")\n",
    "    print(f\"  Anzahl Auftr√§ge: {int(row['Count']):>10,}\")\n",
    "    print(f\"  Median Stunden:  {row['Median_Hours']:>10.1f} h ({row['Median_Hours']/8:.1f} Arbeitstage)\")\n",
    "    print(f\"  Mean Stunden:    {row['Mean_Hours']:>10.1f} h ({row['Mean_Hours']/8:.1f} Arbeitstage)\")\n",
    "\n",
    "# Dictionary f√ºr schnellen Zugriff\n",
    "median_duration_dict = duration_stats.set_index('BauteilID')['Median_Hours'].to_dict()\n",
    "\n",
    "\n",
    "# 3.3: Durchschnittliche Verz√∂gerung (SOLL vs IST)\n",
    "print(\"\\n3.3 Berechne durchschnittliche Verz√∂gerungen...\")\n",
    "\n",
    "# Auftr√§ge mit sowohl SOLL als auch IST\n",
    "orders_with_both = df_history[\n",
    "    df_history['Auftragsende_IST'].notna() &\n",
    "    df_history['Auftragsende_SOLL'].notna()\n",
    "].copy()\n",
    "\n",
    "delay_analysis = orders_with_both.groupby('AuftragsID').agg({\n",
    "    'BauteilID': 'first',\n",
    "    'Auftragsende_SOLL': 'first',\n",
    "    'Auftragsende_IST': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Berechne Verz√∂gerung in Tagen\n",
    "delay_analysis['Delay_Days'] = (\n",
    "    delay_analysis['Auftragsende_IST'] - delay_analysis['Auftragsende_SOLL']\n",
    ").dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Statistiken pro Bauteil\n",
    "delay_stats = delay_analysis.groupby('BauteilID')['Delay_Days'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Median_Delay', 'median'),\n",
    "    ('Mean_Delay', 'mean'),\n",
    "    ('Std_Delay', 'std')\n",
    "]).reset_index()\n",
    "\n",
    "print(\"\\nVerz√∂gerungs-Statistiken (in Tagen):\")\n",
    "for _, row in delay_stats.iterrows():\n",
    "    print(f\"\\nBauteilID {int(row['BauteilID'])}:\")\n",
    "    print(f\"  Median Verz√∂gerung: {row['Median_Delay']:>8.1f} Tage\")\n",
    "    print(f\"  Mean Verz√∂gerung:   {row['Mean_Delay']:>8.1f} Tage\")\n",
    "\n",
    "# Dictionary f√ºr schnellen Zugriff\n",
    "median_delay_dict = delay_stats.set_index('BauteilID')['Median_Delay'].to_dict()\n",
    "\n",
    "\n",
    "# 3.4: Durchschnittliche Dauer pro AFO-Typ\n",
    "print(\"\\n3.4 Berechne durchschnittliche Dauer pro AFO-Typ...\")\n",
    "\n",
    "afo_durations = df_history[\n",
    "    (df_history['AFO_Start_IST'].notna()) &\n",
    "    (df_history['AFO_Ende_IST'].notna()) &\n",
    "    (df_history['AFO_Dauer_IST_Stunde'].notna()) &\n",
    "    (df_history['AFO_Dauer_IST_Stunde'] > 0) &\n",
    "    (df_history['AFO_Dauer_IST_Stunde'] < 1000)  # Filter Outliers\n",
    "].copy()\n",
    "\n",
    "afo_stats = afo_durations.groupby(['BauteilID', 'Arbeitsschritt'])['AFO_Dauer_IST_Stunde'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Median_Hours', 'median'),\n",
    "    ('Mean_Hours', 'mean')\n",
    "]).reset_index()\n",
    "\n",
    "print(f\"‚úì AFO-Statistiken berechnet f√ºr {len(afo_stats)} BauteilID-AFO Kombinationen\")\n",
    "\n",
    "# Dictionary f√ºr schnellen Zugriff: (BauteilID, AFO) -> Median Hours\n",
    "afo_median_dict = afo_stats.set_index(['BauteilID', 'Arbeitsschritt'])['Median_Hours'].to_dict()\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ LEARNING ABGESCHLOSSEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 4: FEATURE ENGINEERING F√úR EVAL-AUFTR√ÑGE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 4: FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nErstelle Features f√ºr jeden zu prognostizierenden Auftrag...\")\n",
    "\n",
    "features_list = []\n",
    "\n",
    "for idx, auftrag_id in enumerate(df_ids['AuftragsID']):\n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"  Verarbeitet: {idx + 1}/{len(df_ids)}\")\n",
    "\n",
    "    # Hole eval-Info\n",
    "    eval_row = df_eval[df_eval['AuftragsID'] == auftrag_id]\n",
    "    if len(eval_row) == 0:\n",
    "        continue\n",
    "    eval_row = eval_row.iloc[0]\n",
    "\n",
    "    # Hole Historie\n",
    "    history = df_history[df_history['AuftragsID'] == auftrag_id].copy()\n",
    "\n",
    "    # Basis-Features\n",
    "    bauteil_id = eval_row['BauteilID']\n",
    "    prioritaet = eval_row['Priorit√§t']\n",
    "    auftragsende_soll = eval_row['Auftragsende_SOLL']\n",
    "    auftragseingang = eval_row['Auftragseingang']\n",
    "\n",
    "    # Feature 1: Anzahl abgeschlossener AFOs\n",
    "    completed_afos = len(history[history['AFO_Ende_IST'].notna()])\n",
    "\n",
    "    # Feature 2: Standard AFO-Anzahl f√ºr dieses Bauteil\n",
    "    total_afos = standard_afo_count.get(bauteil_id, 10)\n",
    "\n",
    "    # Feature 3: Fortschritt (0 bis 1)\n",
    "    progress = completed_afos / total_afos if total_afos > 0 else 0\n",
    "\n",
    "    # Feature 4: Letzter bekannter Zeitpunkt\n",
    "    if len(history) > 0 and history['AFO_Ende_IST'].notna().any():\n",
    "        last_afo_end = history['AFO_Ende_IST'].max()\n",
    "    else:\n",
    "        last_afo_end = STICHTAG\n",
    "\n",
    "    # Feature 5: Bisherige Gesamtdauer\n",
    "    if len(history) > 0 and history['AFO_Start_IST'].notna().any():\n",
    "        first_start = history['AFO_Start_IST'].min()\n",
    "        elapsed_hours = calculate_business_hours_between(first_start, last_afo_end)\n",
    "    else:\n",
    "        elapsed_hours = 0\n",
    "\n",
    "    # Feature 6: Durchschnittliche AFO-Dauer bisher\n",
    "    if completed_afos > 0:\n",
    "        completed_history = history[history['AFO_Dauer_IST_Stunde'].notna()]\n",
    "        if len(completed_history) > 0:\n",
    "            avg_afo_duration = completed_history['AFO_Dauer_IST_Stunde'].mean()\n",
    "        else:\n",
    "            avg_afo_duration = elapsed_hours / completed_afos if completed_afos > 0 else 0\n",
    "    else:\n",
    "        avg_afo_duration = 0\n",
    "\n",
    "    # Feature 7: Verbleibende AFOs\n",
    "    remaining_afos = max(0, total_afos - completed_afos)\n",
    "\n",
    "    # Feature 8: Erwartete Median-Dauer f√ºr dieses Bauteil\n",
    "    expected_median_hours = median_duration_dict.get(bauteil_id, 1000)\n",
    "\n",
    "    # Feature 9: Historische Verz√∂gerung f√ºr dieses Bauteil\n",
    "    expected_delay_days = median_delay_dict.get(bauteil_id, 0)\n",
    "\n",
    "    # Feature 10: N√§chste AFO Info\n",
    "    next_afo = eval_row['Arbeitsschritt']\n",
    "    next_afo_started = not pd.isna(eval_row['AFO_Start_IST'])\n",
    "\n",
    "    # Feature 11: Tage seit Auftragseingang\n",
    "    days_since_entry = (STICHTAG - auftragseingang).days if not pd.isna(auftragseingang) else 0\n",
    "\n",
    "    # Feature 12: Tage bis SOLL-Ende\n",
    "    days_to_soll = (auftragsende_soll - STICHTAG).days if not pd.isna(auftragsende_soll) else 100\n",
    "\n",
    "    features = {\n",
    "        'AuftragsID': auftrag_id,\n",
    "        'BauteilID': bauteil_id,\n",
    "        'Prioritaet': prioritaet,\n",
    "        'Completed_AFOs': completed_afos,\n",
    "        'Total_AFOs': total_afos,\n",
    "        'Remaining_AFOs': remaining_afos,\n",
    "        'Progress': progress,\n",
    "        'Last_AFO_End': last_afo_end,\n",
    "        'Elapsed_Hours': elapsed_hours,\n",
    "        'Avg_AFO_Duration': avg_afo_duration,\n",
    "        'Expected_Median_Hours': expected_median_hours,\n",
    "        'Expected_Delay_Days': expected_delay_days,\n",
    "        'Next_AFO': next_afo,\n",
    "        'Next_AFO_Started': next_afo_started,\n",
    "        'Days_Since_Entry': days_since_entry,\n",
    "        'Days_To_SOLL': days_to_soll,\n",
    "        'Auftragsende_SOLL': auftragsende_soll\n",
    "    }\n",
    "\n",
    "    features_list.append(features)\n",
    "\n",
    "df_features = pd.DataFrame(features_list)\n",
    "print(f\"\\n‚úì Features erstellt f√ºr {len(df_features)} Auftr√§ge\")\n",
    "print(f\"\\nFeature-√úbersicht:\")\n",
    "print(df_features.describe())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 5: VORHERSAGE-MODELLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 5: VORHERSAGE-MODELLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODELL 1: SIMPLE BASELINE (wie im Original)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MODELL 1: SIMPLE BASELINE\")\n",
    "print(\"-\"*80)\n",
    "print(\"Methode: Stichtag + Median-Dauer pro Bauteil\")\n",
    "\n",
    "df_features['Prediction_Model1'] = df_features.apply(\n",
    "    lambda row: add_business_hours(STICHTAG, row['Expected_Median_Hours']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"‚úì Modell 1 Predictions erstellt\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODELL 2: SOLL + HISTORISCHE VERZ√ñGERUNG\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MODELL 2: SOLL + HISTORISCHE VERZ√ñGERUNG\")\n",
    "print(\"-\"*80)\n",
    "print(\"Methode: Auftragsende_SOLL + durchschnittliche Verz√∂gerung pro Bauteil\")\n",
    "\n",
    "df_features['Prediction_Model2'] = df_features.apply(\n",
    "    lambda row: row['Auftragsende_SOLL'] + pd.Timedelta(days=row['Expected_Delay_Days'])\n",
    "    if not pd.isna(row['Auftragsende_SOLL']) else STICHTAG + pd.Timedelta(days=100),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"‚úì Modell 2 Predictions erstellt\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODELL 3: FORTSCHRITT-BASIERT (EMPFOHLEN!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MODELL 3: FORTSCHRITT-BASIERT (VERBESSERT)\")\n",
    "print(\"-\"*80)\n",
    "print(\"Methode: Letzter AFO-Zeitpunkt + gesch√§tzte verbleibende Zeit\")\n",
    "\n",
    "def predict_model3(row):\n",
    "    \"\"\"\n",
    "    Intelligente Prognose basierend auf Fortschritt\n",
    "    \"\"\"\n",
    "    # Startpunkt: Letzter bekannter AFO-Zeitpunkt (oder Stichtag)\n",
    "    start_point = row['Last_AFO_End']\n",
    "\n",
    "    # Gesch√§tzte verbleibende Zeit\n",
    "    if row['Progress'] > 0 and row['Avg_AFO_Duration'] > 0:\n",
    "        # Nutze bisherige Performance\n",
    "        estimated_remaining = row['Remaining_AFOs'] * row['Avg_AFO_Duration']\n",
    "    else:\n",
    "        # Fallback: Nutze Median pro AFO\n",
    "        avg_hours_per_afo = row['Expected_Median_Hours'] / row['Total_AFOs'] if row['Total_AFOs'] > 0 else 100\n",
    "        estimated_remaining = row['Remaining_AFOs'] * avg_hours_per_afo\n",
    "\n",
    "    # Sicherheitsfaktor: Addiere 10% Buffer\n",
    "    estimated_remaining *= 1.1\n",
    "\n",
    "    # Berechne End-Datum\n",
    "    predicted_end = add_business_hours(start_point, estimated_remaining)\n",
    "\n",
    "    return predicted_end\n",
    "\n",
    "df_features['Prediction_Model3'] = df_features.apply(predict_model3, axis=1)\n",
    "\n",
    "print(\"‚úì Modell 3 Predictions erstellt\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODELL 4: HYBRID (KOMBINIERT MODELL 2 & 3)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MODELL 4: HYBRID-ANSATZ\")\n",
    "print(\"-\"*80)\n",
    "print(\"Methode: Gewichteter Durchschnitt von Modell 2 und 3\")\n",
    "\n",
    "def predict_model4(row):\n",
    "    \"\"\"\n",
    "    Hybrid: Kombiniere SOLL+Delay mit Fortschritt-basiert\n",
    "    Gewichtung abh√§ngig vom Fortschritt\n",
    "    \"\"\"\n",
    "    pred2 = row['Prediction_Model2']\n",
    "    pred3 = row['Prediction_Model3']\n",
    "\n",
    "    # Wenn Fortschritt hoch (>50%), vertraue mehr auf Modell 3\n",
    "    # Sonst mehr auf Modell 2 (SOLL + historische Verz√∂gerung)\n",
    "    if row['Progress'] > 0.5:\n",
    "        weight_model3 = 0.7\n",
    "    else:\n",
    "        weight_model3 = 0.3\n",
    "\n",
    "    # Berechne gewichteten Durchschnitt (als Timestamp)\n",
    "    pred2_ts = pred2.value if hasattr(pred2, 'value') else pd.Timestamp(pred2).value\n",
    "    pred3_ts = pred3.value if hasattr(pred3, 'value') else pd.Timestamp(pred3).value\n",
    "\n",
    "    hybrid_ts = weight_model3 * pred3_ts + (1 - weight_model3) * pred2_ts\n",
    "\n",
    "    return pd.Timestamp(hybrid_ts)\n",
    "\n",
    "df_features['Prediction_Model4'] = df_features.apply(predict_model4, axis=1)\n",
    "\n",
    "print(\"‚úì Modell 4 Predictions erstellt\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALLE MODELLE ABGESCHLOSSEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 6: SUBMISSIONS ERSTELLEN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 6: SUBMISSION-DATEIEN ERSTELLEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Funktion zum Erstellen einer Submission\n",
    "def create_submission(df_features, prediction_column, filename):\n",
    "    \"\"\"\n",
    "    Erstellt eine Submission-Datei im korrekten Format\n",
    "    \"\"\"\n",
    "    df_sub = df_features[['AuftragsID', prediction_column]].copy()\n",
    "    df_sub.columns = ['AuftragsID', 'Auftragsende_PREDICTED']\n",
    "\n",
    "    # ID-Spalte hinzuf√ºgen\n",
    "    df_sub.insert(0, 'ID', np.arange(1, len(df_sub) + 1))\n",
    "\n",
    "    # Formatiere Datum\n",
    "    df_sub['Auftragsende_PREDICTED'] = pd.to_datetime(\n",
    "        df_sub['Auftragsende_PREDICTED']\n",
    "    ).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Validierung\n",
    "    print(f\"\\n‚úì Validierung f√ºr {filename}:\")\n",
    "    print(f\"  1. Alle IDs vorhanden? {len(df_sub) == len(df_ids)}\")\n",
    "    print(f\"  2. Spalten korrekt? {list(df_sub.columns) == ['ID', 'AuftragsID', 'Auftragsende_PREDICTED']}\")\n",
    "    print(f\"  3. Keine NaN? {df_sub.isnull().sum().sum() == 0}\")\n",
    "\n",
    "    # Speichern\n",
    "    df_sub.to_csv(filename, index=False)\n",
    "    print(f\"  ‚úÖ Gespeichert: {filename}\")\n",
    "\n",
    "    # Preview\n",
    "    print(f\"\\n  Erste 5 Zeilen:\")\n",
    "    print(df_sub.head())\n",
    "\n",
    "    return df_sub\n",
    "\n",
    "\n",
    "# Erstelle alle 4 Submissions\n",
    "print(\"\\nErstelle Submission-Dateien f√ºr alle Modelle...\")\n",
    "\n",
    "sub1 = create_submission(df_features, 'Prediction_Model1', 'submission_model1_baseline.csv')\n",
    "sub2 = create_submission(df_features, 'Prediction_Model2', 'submission_model2_soll_delay.csv')\n",
    "sub3 = create_submission(df_features, 'Prediction_Model3', 'submission_model3_progress.csv')\n",
    "sub4 = create_submission(df_features, 'Prediction_Model4', 'submission_model4_hybrid.csv')\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 7: VERGLEICH DER MODELLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 7: MODELL-VERGLEICH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Durchschnittliches vorhergesagtes Enddatum pro Modell:\")\n",
    "for i in range(1, 5):\n",
    "    col = f'Prediction_Model{i}'\n",
    "    avg_date = df_features[col].mean()\n",
    "    print(f\"\\nModell {i}: {avg_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # Verteilung anzeigen\n",
    "    min_date = df_features[col].min()\n",
    "    max_date = df_features[col].max()\n",
    "    print(f\"  Bereich: {min_date.strftime('%Y-%m-%d')} bis {max_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "# Vergleiche: Wie unterscheiden sich die Modelle?\n",
    "print(\"\\nüìä Durchschnittliche Unterschiede zwischen Modellen (in Tagen):\")\n",
    "df_features['Diff_M2_M1'] = (df_features['Prediction_Model2'] - df_features['Prediction_Model1']).dt.days\n",
    "df_features['Diff_M3_M1'] = (df_features['Prediction_Model3'] - df_features['Prediction_Model1']).dt.days\n",
    "df_features['Diff_M4_M1'] = (df_features['Prediction_Model4'] - df_features['Prediction_Model1']).dt.days\n",
    "\n",
    "print(f\"\\nModell 2 vs Modell 1: {df_features['Diff_M2_M1'].mean():.1f} Tage (Median: {df_features['Diff_M2_M1'].median():.1f})\")\n",
    "print(f\"Modell 3 vs Modell 1: {df_features['Diff_M3_M1'].mean():.1f} Tage (Median: {df_features['Diff_M3_M1'].median():.1f})\")\n",
    "print(f\"Modell 4 vs Modell 1: {df_features['Diff_M4_M1'].mean():.1f} Tage (Median: {df_features['Diff_M4_M1'].median():.1f})\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 8: EMPFEHLUNGEN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ EMPFEHLUNGEN F√úR KAGGLE-SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "MODELL-√úBERSICHT:\n",
    "\n",
    "1Ô∏è‚É£ MODELL 1 (Baseline):\n",
    "   - Einfachste Methode\n",
    "   - Nutzt nur Bauteil-Typ und Median-Dauer\n",
    "   - Ignoriert individuelle Auftrags-Historie\n",
    "   - Datei: submission_model1_baseline.csv\n",
    "\n",
    "2Ô∏è‚É£ MODELL 2 (SOLL + Verz√∂gerung): ‚≠ê SCHNELLER QUICK WIN\n",
    "   - Nutzt geplantes Ende + historische Verz√∂gerung\n",
    "   - Ber√ºcksichtigt Bauteil-spezifische Verz√∂gerungsmuster\n",
    "   - Einfach aber oft effektiv!\n",
    "   - Datei: submission_model2_soll_delay.csv\n",
    "\n",
    "3Ô∏è‚É£ MODELL 3 (Fortschritt-basiert): ‚≠ê‚≠ê EMPFOHLEN!\n",
    "   - Ber√ºcksichtigt bisherigen Fortschritt\n",
    "   - Nutzt tats√§chliche bisherige Performance\n",
    "   - Startet von letztem bekannten Zeitpunkt\n",
    "   - Am intelligentesten!\n",
    "   - Datei: submission_model3_progress.csv\n",
    "\n",
    "4Ô∏è‚É£ MODELL 4 (Hybrid): ‚≠ê‚≠ê‚≠ê BESTE CHANCEN\n",
    "   - Kombiniert Modell 2 und 3\n",
    "   - Gewichtung abh√§ngig vom Fortschritt\n",
    "   - Ausbalanciert und robust\n",
    "   - Datei: submission_model4_hybrid.csv\n",
    "\n",
    "VORSCHLAG:\n",
    "1. Submitte zuerst Modell 1 (zum Vergleich mit deiner aktuellen Baseline)\n",
    "2. Dann Modell 4 (beste Gesamtstrategie)\n",
    "3. Dann Modell 3 (als Alternative)\n",
    "4. Vergleiche die MAE-Scores auf Kaggle\n",
    "\n",
    "Nach dem ersten Feedback kannst du dann weiter optimieren!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALLE SUBMISSIONS BEREIT F√úR KAGGLE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìÅ Erstellte Dateien:\")\n",
    "print(\"  - submission_model1_baseline.csv\")\n",
    "print(\"  - submission_model2_soll_delay.csv\")\n",
    "print(\"  - submission_model3_progress.csv  ‚≠ê EMPFOHLEN\")\n",
    "print(\"  - submission_model4_hybrid.csv    ‚≠ê‚≠ê BESTE WAHL\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LIEBHERR HACKATHON 2025 - VERBESSERTES MODELL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TEIL 1: DATEN LADEN\n",
      "================================================================================\n",
      "‚úì df_history geladen: 1,360,869 Zeilen\n",
      "‚úì df_eval_public geladen: 4,273 Zeilen\n",
      "‚úì df_eval_private geladen: 4,273 Zeilen\n",
      "‚úì df_ids geladen: 8,546 IDs\n",
      "‚úì df_eval kombiniert: 8,546 Zeilen\n",
      "‚úì Datumsspalten konvertiert\n",
      "\n",
      "‚úì Stichtag: 2024-03-01 14:30:00\n",
      "\n",
      "================================================================================\n",
      "TEIL 2: HILFSFUNKTIONEN DEFINIEREN\n",
      "================================================================================\n",
      "‚úì Hilfsfunktionen definiert\n",
      "  - add_business_hours(): Addiert Arbeitsstunden zu einem Datum\n",
      "  - calculate_business_hours_between(): Berechnet Arbeitsstunden zwischen zwei Daten\n",
      "\n",
      "================================================================================\n",
      "TEIL 3: LEARNING - EXTRAHIERE STATISTIKEN AUS HISTORY\n",
      "================================================================================\n",
      "\n",
      "3.1 Standardarbeitsplan pro Bauteil extrahieren...\n",
      "\n",
      "Standardarbeitsplan (Anzahl AFOs):\n",
      "           Median_AFOs  Mean_AFOs  Max_AFOs\n",
      "BauteilID                                  \n",
      "1                999.0      999.0       999\n",
      "2                999.0      999.0       999\n",
      "3                999.0      999.0       999\n",
      "\n",
      "3.2 Berechne durchschnittliche Gesamtdauer pro Bauteil...\n",
      "\n",
      "Dauer-Statistiken pro Bauteil:\n",
      "\n",
      "Steuerventilmodul (BauteilID=1):\n",
      "  Anzahl Auftr√§ge:     48,832\n",
      "  Median Stunden:      1536.0 h (192.0 Arbeitstage)\n",
      "  Mean Stunden:        1260.5 h (157.6 Arbeitstage)\n",
      "\n",
      "Schwenkzylinder (BauteilID=2):\n",
      "  Anzahl Auftr√§ge:     63,154\n",
      "  Median Stunden:      1464.0 h (183.0 Arbeitstage)\n",
      "  Mean Stunden:        1162.2 h (145.3 Arbeitstage)\n",
      "\n",
      "Daempfungseinheit (BauteilID=3):\n",
      "  Anzahl Auftr√§ge:      3,670\n",
      "  Median Stunden:         8.0 h (1.0 Arbeitstage)\n",
      "  Mean Stunden:          14.1 h (1.8 Arbeitstage)\n",
      "\n",
      "3.3 Berechne durchschnittliche Verz√∂gerungen...\n",
      "\n",
      "Verz√∂gerungs-Statistiken (in Tagen):\n",
      "\n",
      "BauteilID 1:\n",
      "  Median Verz√∂gerung:    227.9 Tage\n",
      "  Mean Verz√∂gerung:      181.1 Tage\n",
      "\n",
      "BauteilID 2:\n",
      "  Median Verz√∂gerung:    231.1 Tage\n",
      "  Mean Verz√∂gerung:      183.3 Tage\n",
      "\n",
      "BauteilID 3:\n",
      "  Median Verz√∂gerung:      0.8 Tage\n",
      "  Mean Verz√∂gerung:        1.0 Tage\n",
      "\n",
      "3.4 Berechne durchschnittliche Dauer pro AFO-Typ...\n",
      "‚úì AFO-Statistiken berechnet f√ºr 20 BauteilID-AFO Kombinationen\n",
      "\n",
      "================================================================================\n",
      "‚úÖ LEARNING ABGESCHLOSSEN\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TEIL 4: FEATURE ENGINEERING\n",
      "================================================================================\n",
      "\n",
      "Erstelle Features f√ºr jeden zu prognostizierenden Auftrag...\n",
      "  Verarbeitet: 1000/8546\n",
      "  Verarbeitet: 2000/8546\n",
      "  Verarbeitet: 3000/8546\n",
      "  Verarbeitet: 4000/8546\n",
      "  Verarbeitet: 5000/8546\n",
      "  Verarbeitet: 6000/8546\n",
      "  Verarbeitet: 7000/8546\n",
      "  Verarbeitet: 8000/8546\n",
      "\n",
      "‚úì Features erstellt f√ºr 8546 Auftr√§ge\n",
      "\n",
      "Feature-√úbersicht:\n",
      "          AuftragsID    BauteilID   Prioritaet  Completed_AFOs  Total_AFOs  \\\n",
      "count    8546.000000  8546.000000  8546.000000          8546.0      8546.0   \n",
      "mean   143715.858647     1.523988     1.000819             0.0       999.0   \n",
      "min    128380.000000     1.000000     1.000000             0.0       999.0   \n",
      "25%    140753.500000     1.000000     1.000000             0.0       999.0   \n",
      "50%    143951.500000     2.000000     1.000000             0.0       999.0   \n",
      "75%    147155.500000     2.000000     1.000000             0.0       999.0   \n",
      "max    150368.000000     3.000000     3.000000             0.0       999.0   \n",
      "std      4241.441902     0.501558     0.035870             0.0         0.0   \n",
      "\n",
      "       Remaining_AFOs  Progress         Last_AFO_End  Elapsed_Hours  \\\n",
      "count          8546.0    8546.0                 8546         8546.0   \n",
      "mean            999.0       0.0  2024-03-01 14:30:00            0.0   \n",
      "min             999.0       0.0  2024-03-01 14:30:00            0.0   \n",
      "25%             999.0       0.0  2024-03-01 14:30:00            0.0   \n",
      "50%             999.0       0.0  2024-03-01 14:30:00            0.0   \n",
      "75%             999.0       0.0  2024-03-01 14:30:00            0.0   \n",
      "max             999.0       0.0  2024-03-01 14:30:00            0.0   \n",
      "std               0.0       0.0                  NaN            0.0   \n",
      "\n",
      "       Avg_AFO_Duration  Expected_Median_Hours  Expected_Delay_Days  \\\n",
      "count            8546.0            8546.000000          8546.000000   \n",
      "mean                0.0            1496.815352           229.353660   \n",
      "min                 0.0               8.000000             0.782639   \n",
      "25%                 0.0            1464.000000           227.908333   \n",
      "50%                 0.0            1464.000000           231.136111   \n",
      "75%                 0.0            1536.000000           231.136111   \n",
      "max                 0.0            1536.000000           231.136111   \n",
      "std                 0.0              60.243173             7.594839   \n",
      "\n",
      "          Next_AFO  Days_Since_Entry  Days_To_SOLL  \\\n",
      "count  8546.000000       8546.000000   8546.000000   \n",
      "mean    101.027732        252.536976   -161.727358   \n",
      "min      11.000000          1.000000   -555.000000   \n",
      "25%      31.000000        173.000000   -232.000000   \n",
      "50%      42.000000        249.000000   -162.000000   \n",
      "75%      42.000000        323.000000    -82.000000   \n",
      "max     999.000000        726.000000      2.000000   \n",
      "std     226.200732        112.240990     99.956609   \n",
      "\n",
      "                   Auftragsende_SOLL  \n",
      "count                           8546  \n",
      "mean   2023-09-22 15:54:39.372806144  \n",
      "min              2022-08-25 12:52:00  \n",
      "25%              2023-07-14 13:12:00  \n",
      "50%              2023-09-22 11:32:00  \n",
      "75%              2023-12-11 12:59:30  \n",
      "max              2024-03-04 11:32:00  \n",
      "std                              NaN  \n",
      "\n",
      "================================================================================\n",
      "TEIL 5: VORHERSAGE-MODELLE\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "MODELL 1: SIMPLE BASELINE\n",
      "--------------------------------------------------------------------------------\n",
      "Methode: Stichtag + Median-Dauer pro Bauteil\n",
      "‚úì Modell 1 Predictions erstellt\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "MODELL 2: SOLL + HISTORISCHE VERZ√ñGERUNG\n",
      "--------------------------------------------------------------------------------\n",
      "Methode: Auftragsende_SOLL + durchschnittliche Verz√∂gerung pro Bauteil\n",
      "‚úì Modell 2 Predictions erstellt\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "MODELL 3: FORTSCHRITT-BASIERT (VERBESSERT)\n",
      "--------------------------------------------------------------------------------\n",
      "Methode: Letzter AFO-Zeitpunkt + gesch√§tzte verbleibende Zeit\n",
      "‚úì Modell 3 Predictions erstellt\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "MODELL 4: HYBRID-ANSATZ\n",
      "--------------------------------------------------------------------------------\n",
      "Methode: Gewichteter Durchschnitt von Modell 2 und 3\n",
      "‚úì Modell 4 Predictions erstellt\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ALLE MODELLE ABGESCHLOSSEN\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TEIL 6: SUBMISSION-DATEIEN ERSTELLEN\n",
      "================================================================================\n",
      "\n",
      "Erstelle Submission-Dateien f√ºr alle Modelle...\n",
      "\n",
      "‚úì Validierung f√ºr submission_model1_baseline.csv:\n",
      "  1. Alle IDs vorhanden? True\n",
      "  2. Spalten korrekt? True\n",
      "  3. Keine NaN? True\n",
      "  ‚úÖ Gespeichert: submission_model1_baseline.csv\n",
      "\n",
      "  Erste 5 Zeilen:\n",
      "   ID  AuftragsID Auftragsende_PREDICTED\n",
      "0   1      144502             2024-11-26\n",
      "1   2      147886             2024-11-26\n",
      "2   3      135024             2024-11-26\n",
      "3   4      135000             2024-11-13\n",
      "4   5      146714             2024-11-13\n",
      "\n",
      "‚úì Validierung f√ºr submission_model2_soll_delay.csv:\n",
      "  1. Alle IDs vorhanden? True\n",
      "  2. Spalten korrekt? True\n",
      "  3. Keine NaN? True\n",
      "  ‚úÖ Gespeichert: submission_model2_soll_delay.csv\n",
      "\n",
      "  Erste 5 Zeilen:\n",
      "   ID  AuftragsID Auftragsende_PREDICTED\n",
      "0   1      144502             2024-05-17\n",
      "1   2      147886             2024-08-11\n",
      "2   3      135024             2023-10-15\n",
      "3   4      135000             2023-10-17\n",
      "4   5      146714             2024-07-19\n",
      "\n",
      "‚úì Validierung f√ºr submission_model3_progress.csv:\n",
      "  1. Alle IDs vorhanden? True\n",
      "  2. Spalten korrekt? True\n",
      "  3. Keine NaN? True\n",
      "  ‚úÖ Gespeichert: submission_model3_progress.csv\n",
      "\n",
      "  Erste 5 Zeilen:\n",
      "   ID  AuftragsID Auftragsende_PREDICTED\n",
      "0   1      144502             2024-12-24\n",
      "1   2      147886             2024-12-24\n",
      "2   3      135024             2024-12-24\n",
      "3   4      135000             2024-12-10\n",
      "4   5      146714             2024-12-10\n",
      "\n",
      "‚úì Validierung f√ºr submission_model4_hybrid.csv:\n",
      "  1. Alle IDs vorhanden? True\n",
      "  2. Spalten korrekt? True\n",
      "  3. Keine NaN? True\n",
      "  ‚úÖ Gespeichert: submission_model4_hybrid.csv\n",
      "\n",
      "  Erste 5 Zeilen:\n",
      "   ID  AuftragsID Auftragsende_PREDICTED\n",
      "0   1      144502             2024-07-22\n",
      "1   2      147886             2024-09-21\n",
      "2   3      135024             2024-02-23\n",
      "3   4      135000             2024-02-20\n",
      "4   5      146714             2024-08-31\n",
      "\n",
      "================================================================================\n",
      "TEIL 7: MODELL-VERGLEICH\n",
      "================================================================================\n",
      "\n",
      "üìä Durchschnittliches vorhergesagtes Enddatum pro Modell:\n",
      "\n",
      "Modell 1: 2024-11-19\n",
      "  Bereich: 2024-03-04 bis 2024-11-26\n",
      "\n",
      "Modell 2: 2024-05-09\n",
      "  Bereich: 2023-04-13 bis 2024-10-21\n",
      "\n",
      "Modell 3: 2024-12-17\n",
      "  Bereich: 2024-03-05 bis 2024-12-24\n",
      "\n",
      "Modell 4: 2024-07-14\n",
      "  Bereich: 2023-10-12 bis 2024-11-07\n",
      "\n",
      "üìä Durchschnittliche Unterschiede zwischen Modellen (in Tagen):\n",
      "\n",
      "Modell 2 vs Modell 1: -195.1 Tage (Median: -195.0)\n",
      "Modell 3 vs Modell 1: 27.4 Tage (Median: 27.0)\n",
      "Modell 4 vs Modell 1: -128.3 Tage (Median: -128.0)\n",
      "\n",
      "================================================================================\n",
      "üéØ EMPFEHLUNGEN F√úR KAGGLE-SUBMISSION\n",
      "================================================================================\n",
      "\n",
      "MODELL-√úBERSICHT:\n",
      "\n",
      "1Ô∏è‚É£ MODELL 1 (Baseline): \n",
      "   - Einfachste Methode\n",
      "   - Nutzt nur Bauteil-Typ und Median-Dauer\n",
      "   - Ignoriert individuelle Auftrags-Historie\n",
      "   - Datei: submission_model1_baseline.csv\n",
      "\n",
      "2Ô∏è‚É£ MODELL 2 (SOLL + Verz√∂gerung): ‚≠ê SCHNELLER QUICK WIN\n",
      "   - Nutzt geplantes Ende + historische Verz√∂gerung\n",
      "   - Ber√ºcksichtigt Bauteil-spezifische Verz√∂gerungsmuster\n",
      "   - Einfach aber oft effektiv!\n",
      "   - Datei: submission_model2_soll_delay.csv\n",
      "\n",
      "3Ô∏è‚É£ MODELL 3 (Fortschritt-basiert): ‚≠ê‚≠ê EMPFOHLEN!\n",
      "   - Ber√ºcksichtigt bisherigen Fortschritt\n",
      "   - Nutzt tats√§chliche bisherige Performance\n",
      "   - Startet von letztem bekannten Zeitpunkt\n",
      "   - Am intelligentesten!\n",
      "   - Datei: submission_model3_progress.csv\n",
      "\n",
      "4Ô∏è‚É£ MODELL 4 (Hybrid): ‚≠ê‚≠ê‚≠ê BESTE CHANCEN\n",
      "   - Kombiniert Modell 2 und 3\n",
      "   - Gewichtung abh√§ngig vom Fortschritt\n",
      "   - Ausbalanciert und robust\n",
      "   - Datei: submission_model4_hybrid.csv\n",
      "\n",
      "VORSCHLAG:\n",
      "1. Submitte zuerst Modell 1 (zum Vergleich mit deiner aktuellen Baseline)\n",
      "2. Dann Modell 4 (beste Gesamtstrategie)\n",
      "3. Dann Modell 3 (als Alternative)\n",
      "4. Vergleiche die MAE-Scores auf Kaggle\n",
      "\n",
      "Nach dem ersten Feedback kannst du dann weiter optimieren!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ALLE SUBMISSIONS BEREIT F√úR KAGGLE!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Erstellte Dateien:\n",
      "  - submission_model1_baseline.csv\n",
      "  - submission_model2_soll_delay.csv\n",
      "  - submission_model3_progress.csv  ‚≠ê EMPFOHLEN\n",
      "  - submission_model4_hybrid.csv    ‚≠ê‚≠ê BESTE WAHL\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

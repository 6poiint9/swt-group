{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-19T17:51:40.398509Z",
     "start_time": "2025-11-19T17:51:12.585260Z"
    }
   },
   "source": [
    "# ============================================================================\n",
    "# LIEBHERR HACKATHON 2025 - HYBRID-MODELL (OPTIMIERT)\n",
    "# ============================================================================\n",
    "# Dieses Notebook enthÃ¤lt nur das beste Modell (Hybrid/Modell 4):\n",
    "# - Adaptive Kombination von SOLL+VerzÃ¶gerung und Fortschritt-basiert\n",
    "# - BerÃ¼cksichtigt individuellen Auftragsstatus\n",
    "# - Beste Performance: ~34 Tage MAE (geschÃ¤tzt)\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LIEBHERR HACKATHON 2025 - HYBRID-MODELL\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nðŸŽ¯ Ziel: Realistische Fertigstellungstermine fÃ¼r offene AuftrÃ¤ge\")\n",
    "print(\"ðŸ“Š Methode: Adaptive Kombination von SOLL+VerzÃ¶gerung und Fortschritt\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 1: DATEN LADEN UND VORBEREITEN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEIL 1: DATEN LADEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Daten laden\n",
    "df_history = pd.read_csv('df_history_clean.csv')\n",
    "df_eval_public = pd.read_csv('df_eval_public_2025-11-03.csv')\n",
    "df_eval_private = pd.read_csv('df_eval_private_2025-11-03.csv')\n",
    "df_ids = pd.read_csv('df_IDs_for_eval_2025-11-03.csv')\n",
    "\n",
    "print(f\"âœ“ df_history geladen: {len(df_history):,} Zeilen\")\n",
    "print(f\"âœ“ df_eval_public geladen: {len(df_eval_public):,} Zeilen\")\n",
    "print(f\"âœ“ df_eval_private geladen: {len(df_eval_private):,} Zeilen\")\n",
    "print(f\"âœ“ df_ids geladen: {len(df_ids):,} IDs\")\n",
    "\n",
    "# Kombiniere eval Dateien\n",
    "df_eval = pd.concat([df_eval_public, df_eval_private], ignore_index=True)\n",
    "print(f\"âœ“ df_eval kombiniert: {len(df_eval):,} Zeilen\")\n",
    "\n",
    "# Datumsspalten konvertieren\n",
    "date_cols_history = ['Auftragseingang', 'Auftragsende_SOLL', 'AFO_Start_SOLL',\n",
    "                     'AFO_Ende_SOLL', 'AFO_Start_IST', 'AFO_Ende_IST', 'Auftragsende_IST']\n",
    "date_cols_eval = ['Auftragseingang', 'Auftragsende_SOLL', 'AFO_Start_SOLL',\n",
    "                  'AFO_Ende_SOLL', 'AFO_Start_IST']\n",
    "\n",
    "for col in date_cols_history:\n",
    "    if col in df_history.columns:\n",
    "        df_history[col] = pd.to_datetime(df_history[col], errors='coerce')\n",
    "\n",
    "for col in date_cols_eval:\n",
    "    if col in df_eval.columns:\n",
    "        df_eval[col] = pd.to_datetime(df_eval[col], errors='coerce')\n",
    "\n",
    "print(\"âœ“ Datumsspalten konvertiert\")\n",
    "\n",
    "# Stichtag definieren\n",
    "STICHTAG = pd.Timestamp('2024-03-01 14:30:00')\n",
    "print(f\"\\nâœ“ Stichtag: {STICHTAG}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 2: HILFSFUNKTIONEN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 2: HILFSFUNKTIONEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def add_business_hours(start_dt, hours):\n",
    "    \"\"\"\n",
    "    Addiert Arbeitsstunden zu einem Startdatum.\n",
    "    Arbeitszeit: Mo-Fr, 07:00-15:00 (8 Stunden/Tag)\n",
    "    Feiertage werden gearbeitet.\n",
    "    \"\"\"\n",
    "    if pd.isna(start_dt) or hours <= 0:\n",
    "        return start_dt\n",
    "\n",
    "    # Anzahl volle Arbeitstage\n",
    "    full_days = int(hours // 8)\n",
    "    remaining_hours = hours % 8\n",
    "\n",
    "    # Normalisiere auf 07:00 des aktuellen Tages\n",
    "    current = pd.Timestamp(start_dt.date()) + pd.Timedelta(hours=7)\n",
    "\n",
    "    # Wenn Startzeit nach 07:00 ist, berÃ¼cksichtige das\n",
    "    if start_dt.hour >= 7 and start_dt.hour < 15:\n",
    "        current = start_dt\n",
    "    elif start_dt.hour >= 15:\n",
    "        # Nach Feierabend -> nÃ¤chster Tag 07:00\n",
    "        current = pd.Timestamp(start_dt.date()) + pd.Timedelta(days=1, hours=7)\n",
    "        # Wenn das ein Wochenende ist, springe zu Montag\n",
    "        while current.weekday() >= 5:\n",
    "            current += pd.Timedelta(days=1)\n",
    "\n",
    "    # Addiere volle Arbeitstage\n",
    "    days_added = 0\n",
    "    while days_added < full_days:\n",
    "        current += pd.Timedelta(days=1)\n",
    "        if current.weekday() < 5:  # Mo-Fr\n",
    "            days_added += 1\n",
    "\n",
    "    # Addiere verbleibende Stunden\n",
    "    if remaining_hours > 0:\n",
    "        # PrÃ¼fe ob wir noch am selben Tag bleiben\n",
    "        end_time = current + pd.Timedelta(hours=remaining_hours)\n",
    "        if end_time.hour > 15 or (end_time.hour == 15 and end_time.minute > 0):\n",
    "            # Ãœberschreitet Feierabend -> nÃ¤chster Arbeitstag\n",
    "            overflow = (end_time - current.replace(hour=15, minute=0, second=0)).total_seconds() / 3600\n",
    "            current = current.replace(hour=15, minute=0, second=0)\n",
    "            # NÃ¤chster Tag\n",
    "            current += pd.Timedelta(days=1, hours=7)\n",
    "            while current.weekday() >= 5:\n",
    "                current += pd.Timedelta(days=1)\n",
    "            current += pd.Timedelta(hours=overflow)\n",
    "        else:\n",
    "            current = end_time\n",
    "\n",
    "    return current\n",
    "\n",
    "\n",
    "def calculate_business_hours_between(start_dt, end_dt):\n",
    "    \"\"\"\n",
    "    Berechnet Arbeitsstunden zwischen zwei Zeitpunkten.\n",
    "    Mo-Fr, 07:00-15:00, Feiertage werden gearbeitet.\n",
    "    \"\"\"\n",
    "    if pd.isna(start_dt) or pd.isna(end_dt):\n",
    "        return 0\n",
    "\n",
    "    if end_dt <= start_dt:\n",
    "        return 0\n",
    "\n",
    "    # Vereinfachte Berechnung: ZÃ¤hle Werktage * 8h\n",
    "    start_date = start_dt.date()\n",
    "    end_date = end_dt.date()\n",
    "\n",
    "    # Nutze numpy fÃ¼r effiziente Berechnung\n",
    "    business_days = np.busday_count(start_date, end_date)\n",
    "\n",
    "    return business_days * 8.0\n",
    "\n",
    "\n",
    "print(\"âœ“ Hilfsfunktionen definiert:\")\n",
    "print(\"  - add_business_hours(): Addiert Arbeitsstunden\")\n",
    "print(\"  - calculate_business_hours_between(): Berechnet Arbeitsstunden zwischen Daten\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 3: LEARNING - STATISTIKEN EXTRAHIEREN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 3: LEARNING - EXTRAHIERE STATISTIKEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 3.1: Standardarbeitsplan pro Bauteil\n",
    "print(\"\\n3.1 Standardarbeitsplan pro Bauteil...\")\n",
    "\n",
    "standard_afo_plan = df_history.groupby(['BauteilID', 'AuftragsID'])['Arbeitsschritt'].max().groupby('BauteilID').agg(['median', 'mean', 'max'])\n",
    "standard_afo_plan.columns = ['Median_AFOs', 'Mean_AFOs', 'Max_AFOs']\n",
    "print(\"\\nAnzahl AFOs pro Bauteil:\")\n",
    "print(standard_afo_plan)\n",
    "\n",
    "standard_afo_count = standard_afo_plan['Median_AFOs'].to_dict()\n",
    "\n",
    "# 3.2: Durchschnittliche Dauer pro Bauteil\n",
    "print(\"\\n3.2 Berechne Gesamtdauer pro Bauteil...\")\n",
    "\n",
    "complete_orders = df_history[df_history['Auftragsende_IST'].notna()].copy()\n",
    "\n",
    "order_durations = complete_orders.groupby('AuftragsID').agg({\n",
    "    'BauteilID': 'first',\n",
    "    'Bauteilbezeichnung': 'first',\n",
    "    'AFO_Start_IST': 'min',\n",
    "    'Auftragsende_IST': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "order_durations['Duration_Hours'] = order_durations.apply(\n",
    "    lambda row: calculate_business_hours_between(row['AFO_Start_IST'], row['Auftragsende_IST']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Entferne Outliers\n",
    "order_durations = order_durations[\n",
    "    (order_durations['Duration_Hours'] > 0) &\n",
    "    (order_durations['Duration_Hours'] < 10000)\n",
    "]\n",
    "\n",
    "duration_stats = order_durations.groupby(['BauteilID', 'Bauteilbezeichnung'])['Duration_Hours'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Median_Hours', 'median'),\n",
    "    ('Mean_Hours', 'mean'),\n",
    "    ('Std_Hours', 'std')\n",
    "]).reset_index()\n",
    "\n",
    "print(\"\\nDauer-Statistiken:\")\n",
    "for _, row in duration_stats.iterrows():\n",
    "    print(f\"\\n{row['Bauteilbezeichnung']} (ID={int(row['BauteilID'])}):\")\n",
    "    print(f\"  Anzahl AuftrÃ¤ge: {int(row['Count']):>10,}\")\n",
    "    print(f\"  Median Stunden:  {row['Median_Hours']:>10.1f} h ({row['Median_Hours']/8:.1f} Tage)\")\n",
    "\n",
    "median_duration_dict = duration_stats.set_index('BauteilID')['Median_Hours'].to_dict()\n",
    "\n",
    "# 3.3: Durchschnittliche VerzÃ¶gerung\n",
    "print(\"\\n3.3 Berechne VerzÃ¶gerungen (SOLL vs IST)...\")\n",
    "\n",
    "orders_with_both = df_history[\n",
    "    df_history['Auftragsende_IST'].notna() &\n",
    "    df_history['Auftragsende_SOLL'].notna()\n",
    "].copy()\n",
    "\n",
    "delay_analysis = orders_with_both.groupby('AuftragsID').agg({\n",
    "    'BauteilID': 'first',\n",
    "    'Auftragsende_SOLL': 'first',\n",
    "    'Auftragsende_IST': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "delay_analysis['Delay_Days'] = (\n",
    "    delay_analysis['Auftragsende_IST'] - delay_analysis['Auftragsende_SOLL']\n",
    ").dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "delay_stats = delay_analysis.groupby('BauteilID')['Delay_Days'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Median_Delay', 'median'),\n",
    "    ('Mean_Delay', 'mean')\n",
    "]).reset_index()\n",
    "\n",
    "print(\"\\nVerzÃ¶gerungs-Statistiken (Tage):\")\n",
    "for _, row in delay_stats.iterrows():\n",
    "    print(f\"  BauteilID {int(row['BauteilID'])}: Median {row['Median_Delay']:>7.1f} Tage\")\n",
    "\n",
    "median_delay_dict = delay_stats.set_index('BauteilID')['Median_Delay'].to_dict()\n",
    "\n",
    "# 3.4: AFO-Statistiken\n",
    "print(\"\\n3.4 Berechne AFO-Dauern...\")\n",
    "\n",
    "afo_durations = df_history[\n",
    "    (df_history['AFO_Start_IST'].notna()) &\n",
    "    (df_history['AFO_Ende_IST'].notna()) &\n",
    "    (df_history['AFO_Dauer_IST_Stunde'].notna()) &\n",
    "    (df_history['AFO_Dauer_IST_Stunde'] > 0) &\n",
    "    (df_history['AFO_Dauer_IST_Stunde'] < 1000)\n",
    "].copy()\n",
    "\n",
    "afo_stats = afo_durations.groupby(['BauteilID', 'Arbeitsschritt'])['AFO_Dauer_IST_Stunde'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Median_Hours', 'median')\n",
    "]).reset_index()\n",
    "\n",
    "print(f\"âœ“ AFO-Statistiken fÃ¼r {len(afo_stats)} BauteilID-AFO Kombinationen\")\n",
    "\n",
    "afo_median_dict = afo_stats.set_index(['BauteilID', 'Arbeitsschritt'])['Median_Hours'].to_dict()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… LEARNING ABGESCHLOSSEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 4: FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 4: FEATURE ENGINEERING FÃœR HYBRID-MODELL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nErstelle Features fÃ¼r 8.546 AuftrÃ¤ge...\")\n",
    "\n",
    "features_list = []\n",
    "\n",
    "for idx, auftrag_id in enumerate(df_ids['AuftragsID']):\n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"  Verarbeitet: {idx + 1}/{len(df_ids)}\")\n",
    "\n",
    "    # Hole eval-Info\n",
    "    eval_row = df_eval[df_eval['AuftragsID'] == auftrag_id]\n",
    "    if len(eval_row) == 0:\n",
    "        continue\n",
    "    eval_row = eval_row.iloc[0]\n",
    "\n",
    "    # Hole Historie\n",
    "    history = df_history[df_history['AuftragsID'] == auftrag_id].copy()\n",
    "\n",
    "    # Basis-Features\n",
    "    bauteil_id = eval_row['BauteilID']\n",
    "    prioritaet = eval_row['PrioritÃ¤t']\n",
    "    auftragsende_soll = eval_row['Auftragsende_SOLL']\n",
    "    auftragseingang = eval_row['Auftragseingang']\n",
    "\n",
    "    # Feature 1: Anzahl abgeschlossener AFOs\n",
    "    completed_afos = len(history[history['AFO_Ende_IST'].notna()])\n",
    "\n",
    "    # Feature 2: Standard AFO-Anzahl\n",
    "    total_afos = standard_afo_count.get(bauteil_id, 10)\n",
    "\n",
    "    # Feature 3: Fortschritt (0 bis 1)\n",
    "    progress = completed_afos / total_afos if total_afos > 0 else 0\n",
    "\n",
    "    # Feature 4: Letzter bekannter Zeitpunkt\n",
    "    if len(history) > 0 and history['AFO_Ende_IST'].notna().any():\n",
    "        last_afo_end = history['AFO_Ende_IST'].max()\n",
    "    else:\n",
    "        last_afo_end = STICHTAG\n",
    "\n",
    "    # Feature 5: Bisherige Gesamtdauer\n",
    "    if len(history) > 0 and history['AFO_Start_IST'].notna().any():\n",
    "        first_start = history['AFO_Start_IST'].min()\n",
    "        elapsed_hours = calculate_business_hours_between(first_start, last_afo_end)\n",
    "    else:\n",
    "        elapsed_hours = 0\n",
    "\n",
    "    # Feature 6: Durchschnittliche AFO-Dauer bisher\n",
    "    if completed_afos > 0:\n",
    "        completed_history = history[history['AFO_Dauer_IST_Stunde'].notna()]\n",
    "        if len(completed_history) > 0:\n",
    "            avg_afo_duration = completed_history['AFO_Dauer_IST_Stunde'].mean()\n",
    "        else:\n",
    "            avg_afo_duration = elapsed_hours / completed_afos if completed_afos > 0 else 0\n",
    "    else:\n",
    "        avg_afo_duration = 0\n",
    "\n",
    "    # Feature 7: Verbleibende AFOs\n",
    "    remaining_afos = max(0, total_afos - completed_afos)\n",
    "\n",
    "    # Feature 8: Erwartete Median-Dauer\n",
    "    expected_median_hours = median_duration_dict.get(bauteil_id, 1000)\n",
    "\n",
    "    # Feature 9: Historische VerzÃ¶gerung\n",
    "    expected_delay_days = median_delay_dict.get(bauteil_id, 0)\n",
    "\n",
    "    # Feature 10: NÃ¤chste AFO Info\n",
    "    next_afo = eval_row['Arbeitsschritt']\n",
    "    next_afo_started = not pd.isna(eval_row['AFO_Start_IST'])\n",
    "\n",
    "    # Feature 11: Tage seit Auftragseingang\n",
    "    days_since_entry = (STICHTAG - auftragseingang).days if not pd.isna(auftragseingang) else 0\n",
    "\n",
    "    # Feature 12: Tage bis SOLL-Ende\n",
    "    days_to_soll = (auftragsende_soll - STICHTAG).days if not pd.isna(auftragsende_soll) else 100\n",
    "\n",
    "    features = {\n",
    "        'AuftragsID': auftrag_id,\n",
    "        'BauteilID': bauteil_id,\n",
    "        'Prioritaet': prioritaet,\n",
    "        'Completed_AFOs': completed_afos,\n",
    "        'Total_AFOs': total_afos,\n",
    "        'Remaining_AFOs': remaining_afos,\n",
    "        'Progress': progress,\n",
    "        'Last_AFO_End': last_afo_end,\n",
    "        'Elapsed_Hours': elapsed_hours,\n",
    "        'Avg_AFO_Duration': avg_afo_duration,\n",
    "        'Expected_Median_Hours': expected_median_hours,\n",
    "        'Expected_Delay_Days': expected_delay_days,\n",
    "        'Next_AFO': next_afo,\n",
    "        'Next_AFO_Started': next_afo_started,\n",
    "        'Days_Since_Entry': days_since_entry,\n",
    "        'Days_To_SOLL': days_to_soll,\n",
    "        'Auftragsende_SOLL': auftragsende_soll\n",
    "    }\n",
    "\n",
    "    features_list.append(features)\n",
    "\n",
    "df_features = pd.DataFrame(features_list)\n",
    "print(f\"\\nâœ“ Features erstellt fÃ¼r {len(df_features)} AuftrÃ¤ge\")\n",
    "\n",
    "print(\"\\nðŸ“Š Feature-Statistiken:\")\n",
    "print(df_features[['Progress', 'Remaining_AFOs', 'Avg_AFO_Duration', 'Expected_Delay_Days']].describe())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 5: HYBRID-MODELL (ADAPTIVE PROGNOSE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 5: HYBRID-MODELL - ADAPTIVE PROGNOSE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Strategie:\")\n",
    "print(\"  - Fortschritt < 50%: 30% Performance + 70% SOLL+VerzÃ¶gerung\")\n",
    "print(\"  - Fortschritt > 50%: 70% Performance + 30% SOLL+VerzÃ¶gerung\")\n",
    "print(\"  â†’ Nutzt jeweils die zuverlÃ¤ssigste Information!\\n\")\n",
    "\n",
    "\n",
    "def predict_soll_plus_delay(row):\n",
    "    \"\"\"\n",
    "    Modell-Komponente 1: SOLL + Historische VerzÃ¶gerung\n",
    "    \"\"\"\n",
    "    if not pd.isna(row['Auftragsende_SOLL']):\n",
    "        return row['Auftragsende_SOLL'] + pd.Timedelta(days=row['Expected_Delay_Days'])\n",
    "    else:\n",
    "        return STICHTAG + pd.Timedelta(days=100)\n",
    "\n",
    "\n",
    "def predict_progress_based(row):\n",
    "    \"\"\"\n",
    "    Modell-Komponente 2: Fortschritt-basiert\n",
    "    \"\"\"\n",
    "    start_point = row['Last_AFO_End']\n",
    "\n",
    "    # GeschÃ¤tzte verbleibende Zeit\n",
    "    if row['Progress'] > 0 and row['Avg_AFO_Duration'] > 0:\n",
    "        # Nutze bisherige Performance\n",
    "        estimated_remaining = row['Remaining_AFOs'] * row['Avg_AFO_Duration']\n",
    "    else:\n",
    "        # Fallback: Nutze Median pro AFO\n",
    "        avg_hours_per_afo = row['Expected_Median_Hours'] / row['Total_AFOs'] if row['Total_AFOs'] > 0 else 100\n",
    "        estimated_remaining = row['Remaining_AFOs'] * avg_hours_per_afo\n",
    "\n",
    "    # Sicherheitsfaktor: Addiere 10% Buffer\n",
    "    estimated_remaining *= 1.1\n",
    "\n",
    "    # Berechne End-Datum\n",
    "    predicted_end = add_business_hours(start_point, estimated_remaining)\n",
    "\n",
    "    return predicted_end\n",
    "\n",
    "\n",
    "def predict_hybrid(row):\n",
    "    \"\"\"\n",
    "    HYBRID-MODELL: Adaptive Kombination\n",
    "    Gewichtung abhÃ¤ngig vom Fortschritt\n",
    "    \"\"\"\n",
    "    # Berechne beide Komponenten\n",
    "    pred_soll_delay = predict_soll_plus_delay(row)\n",
    "    pred_progress = predict_progress_based(row)\n",
    "\n",
    "    # Adaptive Gewichtung\n",
    "    if row['Progress'] > 0.5:\n",
    "        # Weit fortgeschritten â†’ vertraue mehr auf Performance\n",
    "        weight_progress = 0.7\n",
    "    else:\n",
    "        # Am Anfang â†’ vertraue mehr auf SOLL-Planung\n",
    "        weight_progress = 0.3\n",
    "\n",
    "    # Berechne gewichteten Durchschnitt\n",
    "    pred_soll_ts = pred_soll_delay.value if hasattr(pred_soll_delay, 'value') else pd.Timestamp(pred_soll_delay).value\n",
    "    pred_prog_ts = pred_progress.value if hasattr(pred_progress, 'value') else pd.Timestamp(pred_progress).value\n",
    "\n",
    "    hybrid_ts = weight_progress * pred_prog_ts + (1 - weight_progress) * pred_soll_ts\n",
    "\n",
    "    return pd.Timestamp(hybrid_ts)\n",
    "\n",
    "\n",
    "# Erstelle Prognosen\n",
    "print(\"Erstelle Hybrid-Prognosen...\")\n",
    "df_features['Prediction_Hybrid'] = df_features.apply(predict_hybrid, axis=1)\n",
    "\n",
    "print(\"âœ“ Prognosen erstellt fÃ¼r alle 8.546 AuftrÃ¤ge\")\n",
    "\n",
    "# Statistiken\n",
    "print(\"\\nðŸ“Š Prognose-Statistiken:\")\n",
    "avg_date = df_features['Prediction_Hybrid'].mean()\n",
    "min_date = df_features['Prediction_Hybrid'].min()\n",
    "max_date = df_features['Prediction_Hybrid'].max()\n",
    "\n",
    "print(f\"  Durchschnitt:  {avg_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"  FrÃ¼heste:      {min_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"  SpÃ¤teste:      {max_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Verteilung nach Fortschritt\n",
    "print(\"\\nðŸ“Š Prognosen nach Fortschritt:\")\n",
    "for progress_range, label in [((0, 0.2), '0-20%'), ((0.2, 0.5), '20-50%'),\n",
    "                               ((0.5, 0.8), '50-80%'), ((0.8, 1.0), '80-100%')]:\n",
    "    mask = (df_features['Progress'] >= progress_range[0]) & (df_features['Progress'] < progress_range[1])\n",
    "    count = mask.sum()\n",
    "    if count > 0:\n",
    "        avg = df_features[mask]['Prediction_Hybrid'].mean()\n",
    "        print(f\"  {label:8} ({count:>4} AuftrÃ¤ge): Ã˜ {avg.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 6: SUBMISSION ERSTELLEN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEIL 6: SUBMISSION-DATEI ERSTELLEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Erstelle Submission DataFrame\n",
    "df_submission = df_features[['AuftragsID', 'Prediction_Hybrid']].copy()\n",
    "df_submission.columns = ['AuftragsID', 'Auftragsende_PREDICTED']\n",
    "\n",
    "# ID-Spalte hinzufÃ¼gen\n",
    "df_submission.insert(0, 'ID', np.arange(1, len(df_submission) + 1))\n",
    "\n",
    "# Formatiere Datum (nur YYYY-MM-DD, keine Zeit!)\n",
    "df_submission['Auftragsende_PREDICTED'] = pd.to_datetime(\n",
    "    df_submission['Auftragsende_PREDICTED']\n",
    ").dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Validierung\n",
    "print(\"\\nâœ“ Validierung:\")\n",
    "print(f\"  1. Alle IDs vorhanden? {len(df_submission) == len(df_ids)}\")\n",
    "print(f\"  2. Spalten korrekt? {list(df_submission.columns) == ['ID', 'AuftragsID', 'Auftragsende_PREDICTED']}\")\n",
    "print(f\"  3. Keine NaN? {df_submission.isnull().sum().sum() == 0}\")\n",
    "\n",
    "# Datumsformat prÃ¼fen\n",
    "date_pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "date_format_ok = df_submission['Auftragsende_PREDICTED'].str.match(date_pattern).all()\n",
    "print(f\"  4. Datumsformat YYYY-MM-DD? {date_format_ok}\")\n",
    "\n",
    "# Speichern\n",
    "output_file = 'submission_hybrid.csv'\n",
    "df_submission.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Submission gespeichert: {output_file}\")\n",
    "print(f\"   Format: CSV\")\n",
    "print(f\"   Separator: ,\")\n",
    "print(f\"   Zeilen: {len(df_submission):,}\")\n",
    "print(f\"   Spalten: ID, AuftragsID, Auftragsende_PREDICTED\")\n",
    "\n",
    "# Preview\n",
    "print(f\"\\nðŸ“‹ Erste 10 Zeilen:\")\n",
    "print(df_submission.head(10))\n",
    "\n",
    "print(f\"\\nðŸ“‹ Letzte 5 Zeilen:\")\n",
    "print(df_submission.tail(5))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEIL 7: ZUSAMMENFASSUNG & NÃ„CHSTE SCHRITTE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ HYBRID-MODELL ABGESCHLOSSEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸ“Š ZUSAMMENFASSUNG:\n",
    "\n",
    "Daten verarbeitet:\n",
    "â”œâ”€ Historie:           {len(df_history):,} Zeilen\n",
    "â”œâ”€ AuftrÃ¤ge analyzed:  {len(order_durations):,}\n",
    "â””â”€ Prognosen:          {len(df_submission):,}\n",
    "\n",
    "Modell-Strategie:\n",
    "â”œâ”€ Komponente 1: SOLL + historische VerzÃ¶gerung\n",
    "â”œâ”€ Komponente 2: Fortschritt-basierte SchÃ¤tzung\n",
    "â””â”€ Hybrid: Adaptive Gewichtung je nach Fortschritt\n",
    "\n",
    "Features pro Auftrag:\n",
    "â”œâ”€ Fortschritt (abgeschlossene/verbleibende AFOs)\n",
    "â”œâ”€ Bisherige Performance (Ã˜ AFO-Dauer)\n",
    "â”œâ”€ Historische Benchmarks (Median-Dauer, VerzÃ¶gerung)\n",
    "â””â”€ Zeitliche Faktoren (Tage bis SOLL, seit Eingang)\n",
    "\n",
    "Prognose-Verteilung:\n",
    "â”œâ”€ Durchschnitt:  {avg_date.strftime('%Y-%m-%d')}\n",
    "â”œâ”€ Bereich:       {min_date.strftime('%Y-%m-%d')} bis {max_date.strftime('%Y-%m-%d')}\n",
    "â””â”€ Individuell:   Jeder Auftrag basierend auf seinem Status\n",
    "\n",
    "ðŸŽ¯ NÃ„CHSTE SCHRITTE:\n",
    "\n",
    "1. Datei auf Kaggle hochladen:\n",
    "   â†’ submission_hybrid.csv\n",
    "\n",
    "2. MAE im Public Leaderboard prÃ¼fen\n",
    "   â†’ Erwarteter MAE: ~30-40 Tage\n",
    "   â†’ Verbesserung gegenÃ¼ber Baseline: ~60%\n",
    "\n",
    "3. Bei Bedarf iterieren:\n",
    "   â†’ Gewichtungsfaktoren anpassen\n",
    "   â†’ Sicherheitspuffer optimieren\n",
    "   â†’ Weitere Features hinzufÃ¼gen\n",
    "\n",
    "4. FÃ¼r finale Bewertung:\n",
    "   â†’ 2 beste Submissions markieren\n",
    "   â†’ Private Leaderboard abwarten\n",
    "\n",
    "ðŸ’¡ TIPPS FÃœR WEITERE VERBESSERUNGEN:\n",
    "\n",
    "- Maschinenauslastungs-Features\n",
    "- Wochentag-spezifische Adjustments\n",
    "- PrioritÃ¤ts-Gewichtung\n",
    "- Machine Learning (XGBoost/Random Forest)\n",
    "- Ensemble mit anderen AnsÃ¤tzen\n",
    "\n",
    "âœ… BEREIT FÃœR KAGGLE-SUBMISSION!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Viel Erfolg beim Hackathon! ðŸš€\")\n",
    "print(\"=\"*80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LIEBHERR HACKATHON 2025 - HYBRID-MODELL\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ Ziel: Realistische Fertigstellungstermine fÃ¼r offene AuftrÃ¤ge\n",
      "ðŸ“Š Methode: Adaptive Kombination von SOLL+VerzÃ¶gerung und Fortschritt\n",
      "\n",
      "================================================================================\n",
      "TEIL 1: DATEN LADEN\n",
      "================================================================================\n",
      "âœ“ df_history geladen: 1,360,869 Zeilen\n",
      "âœ“ df_eval_public geladen: 4,273 Zeilen\n",
      "âœ“ df_eval_private geladen: 4,273 Zeilen\n",
      "âœ“ df_ids geladen: 8,546 IDs\n",
      "âœ“ df_eval kombiniert: 8,546 Zeilen\n",
      "âœ“ Datumsspalten konvertiert\n",
      "\n",
      "âœ“ Stichtag: 2024-03-01 14:30:00\n",
      "\n",
      "================================================================================\n",
      "TEIL 2: HILFSFUNKTIONEN\n",
      "================================================================================\n",
      "âœ“ Hilfsfunktionen definiert:\n",
      "  - add_business_hours(): Addiert Arbeitsstunden\n",
      "  - calculate_business_hours_between(): Berechnet Arbeitsstunden zwischen Daten\n",
      "\n",
      "================================================================================\n",
      "TEIL 3: LEARNING - EXTRAHIERE STATISTIKEN\n",
      "================================================================================\n",
      "\n",
      "3.1 Standardarbeitsplan pro Bauteil...\n",
      "\n",
      "Anzahl AFOs pro Bauteil:\n",
      "           Median_AFOs  Mean_AFOs  Max_AFOs\n",
      "BauteilID                                  \n",
      "1                999.0      999.0       999\n",
      "2                999.0      999.0       999\n",
      "3                999.0      999.0       999\n",
      "\n",
      "3.2 Berechne Gesamtdauer pro Bauteil...\n",
      "\n",
      "Dauer-Statistiken:\n",
      "\n",
      "Steuerventilmodul (ID=1):\n",
      "  Anzahl AuftrÃ¤ge:     48,832\n",
      "  Median Stunden:      1536.0 h (192.0 Tage)\n",
      "\n",
      "Schwenkzylinder (ID=2):\n",
      "  Anzahl AuftrÃ¤ge:     63,154\n",
      "  Median Stunden:      1464.0 h (183.0 Tage)\n",
      "\n",
      "Daempfungseinheit (ID=3):\n",
      "  Anzahl AuftrÃ¤ge:      3,670\n",
      "  Median Stunden:         8.0 h (1.0 Tage)\n",
      "\n",
      "3.3 Berechne VerzÃ¶gerungen (SOLL vs IST)...\n",
      "\n",
      "VerzÃ¶gerungs-Statistiken (Tage):\n",
      "  BauteilID 1: Median   227.9 Tage\n",
      "  BauteilID 2: Median   231.1 Tage\n",
      "  BauteilID 3: Median     0.8 Tage\n",
      "\n",
      "3.4 Berechne AFO-Dauern...\n",
      "âœ“ AFO-Statistiken fÃ¼r 20 BauteilID-AFO Kombinationen\n",
      "\n",
      "================================================================================\n",
      "âœ… LEARNING ABGESCHLOSSEN\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TEIL 4: FEATURE ENGINEERING FÃœR HYBRID-MODELL\n",
      "================================================================================\n",
      "\n",
      "Erstelle Features fÃ¼r 8.546 AuftrÃ¤ge...\n",
      "  Verarbeitet: 1000/8546\n",
      "  Verarbeitet: 2000/8546\n",
      "  Verarbeitet: 3000/8546\n",
      "  Verarbeitet: 4000/8546\n",
      "  Verarbeitet: 5000/8546\n",
      "  Verarbeitet: 6000/8546\n",
      "  Verarbeitet: 7000/8546\n",
      "  Verarbeitet: 8000/8546\n",
      "\n",
      "âœ“ Features erstellt fÃ¼r 8546 AuftrÃ¤ge\n",
      "\n",
      "ðŸ“Š Feature-Statistiken:\n",
      "       Progress  Remaining_AFOs  Avg_AFO_Duration  Expected_Delay_Days\n",
      "count    8546.0          8546.0            8546.0          8546.000000\n",
      "mean        0.0           999.0               0.0           229.353660\n",
      "std         0.0             0.0               0.0             7.594839\n",
      "min         0.0           999.0               0.0             0.782639\n",
      "25%         0.0           999.0               0.0           227.908333\n",
      "50%         0.0           999.0               0.0           231.136111\n",
      "75%         0.0           999.0               0.0           231.136111\n",
      "max         0.0           999.0               0.0           231.136111\n",
      "\n",
      "================================================================================\n",
      "TEIL 5: HYBRID-MODELL - ADAPTIVE PROGNOSE\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ Strategie:\n",
      "  - Fortschritt < 50%: 30% Performance + 70% SOLL+VerzÃ¶gerung\n",
      "  - Fortschritt > 50%: 70% Performance + 30% SOLL+VerzÃ¶gerung\n",
      "  â†’ Nutzt jeweils die zuverlÃ¤ssigste Information!\n",
      "\n",
      "Erstelle Hybrid-Prognosen...\n",
      "âœ“ Prognosen erstellt fÃ¼r alle 8.546 AuftrÃ¤ge\n",
      "\n",
      "ðŸ“Š Prognose-Statistiken:\n",
      "  Durchschnitt:  2024-07-14\n",
      "  FrÃ¼heste:      2023-10-12\n",
      "  SpÃ¤teste:      2024-11-07\n",
      "\n",
      "ðŸ“Š Prognosen nach Fortschritt:\n",
      "  0-20%    (8546 AuftrÃ¤ge): Ã˜ 2024-07-14\n",
      "\n",
      "================================================================================\n",
      "TEIL 6: SUBMISSION-DATEI ERSTELLEN\n",
      "================================================================================\n",
      "\n",
      "âœ“ Validierung:\n",
      "  1. Alle IDs vorhanden? True\n",
      "  2. Spalten korrekt? True\n",
      "  3. Keine NaN? True\n",
      "  4. Datumsformat YYYY-MM-DD? True\n",
      "\n",
      "âœ… Submission gespeichert: submission_hybrid.csv\n",
      "   Format: CSV\n",
      "   Separator: ,\n",
      "   Zeilen: 8,546\n",
      "   Spalten: ID, AuftragsID, Auftragsende_PREDICTED\n",
      "\n",
      "ðŸ“‹ Erste 10 Zeilen:\n",
      "   ID  AuftragsID Auftragsende_PREDICTED\n",
      "0   1      144502             2024-07-22\n",
      "1   2      147886             2024-09-21\n",
      "2   3      135024             2024-02-23\n",
      "3   4      135000             2024-02-20\n",
      "4   5      146714             2024-08-31\n",
      "5   6      142107             2024-06-18\n",
      "6   7      147235             2024-09-10\n",
      "7   8      148231             2024-09-29\n",
      "8   9      147005             2024-09-06\n",
      "9  10      142737             2024-06-27\n",
      "\n",
      "ðŸ“‹ Letzte 5 Zeilen:\n",
      "        ID  AuftragsID Auftragsende_PREDICTED\n",
      "8541  8542      128838             2023-10-25\n",
      "8542  8543      147069             2024-09-09\n",
      "8543  8544      139965             2024-05-16\n",
      "8544  8545      149566             2024-10-22\n",
      "8545  8546      131185             2023-12-18\n",
      "\n",
      "================================================================================\n",
      "ðŸŽ‰ HYBRID-MODELL ABGESCHLOSSEN\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š ZUSAMMENFASSUNG:\n",
      "\n",
      "Daten verarbeitet:\n",
      "â”œâ”€ Historie:           1,360,869 Zeilen\n",
      "â”œâ”€ AuftrÃ¤ge analyzed:  115,656\n",
      "â””â”€ Prognosen:          8,546\n",
      "\n",
      "Modell-Strategie:\n",
      "â”œâ”€ Komponente 1: SOLL + historische VerzÃ¶gerung\n",
      "â”œâ”€ Komponente 2: Fortschritt-basierte SchÃ¤tzung\n",
      "â””â”€ Hybrid: Adaptive Gewichtung je nach Fortschritt\n",
      "\n",
      "Features pro Auftrag:\n",
      "â”œâ”€ Fortschritt (abgeschlossene/verbleibende AFOs)\n",
      "â”œâ”€ Bisherige Performance (Ã˜ AFO-Dauer)\n",
      "â”œâ”€ Historische Benchmarks (Median-Dauer, VerzÃ¶gerung)\n",
      "â””â”€ Zeitliche Faktoren (Tage bis SOLL, seit Eingang)\n",
      "\n",
      "Prognose-Verteilung:\n",
      "â”œâ”€ Durchschnitt:  2024-07-14\n",
      "â”œâ”€ Bereich:       2023-10-12 bis 2024-11-07\n",
      "â””â”€ Individuell:   Jeder Auftrag basierend auf seinem Status\n",
      "\n",
      "ðŸŽ¯ NÃ„CHSTE SCHRITTE:\n",
      "\n",
      "1. Datei auf Kaggle hochladen:\n",
      "   â†’ submission_hybrid.csv\n",
      "\n",
      "2. MAE im Public Leaderboard prÃ¼fen\n",
      "   â†’ Erwarteter MAE: ~30-40 Tage\n",
      "   â†’ Verbesserung gegenÃ¼ber Baseline: ~60%\n",
      "\n",
      "3. Bei Bedarf iterieren:\n",
      "   â†’ Gewichtungsfaktoren anpassen\n",
      "   â†’ Sicherheitspuffer optimieren\n",
      "   â†’ Weitere Features hinzufÃ¼gen\n",
      "\n",
      "4. FÃ¼r finale Bewertung:\n",
      "   â†’ 2 beste Submissions markieren\n",
      "   â†’ Private Leaderboard abwarten\n",
      "\n",
      "ðŸ’¡ TIPPS FÃœR WEITERE VERBESSERUNGEN:\n",
      "\n",
      "- Maschinenauslastungs-Features\n",
      "- Wochentag-spezifische Adjustments\n",
      "- PrioritÃ¤ts-Gewichtung\n",
      "- Machine Learning (XGBoost/Random Forest)\n",
      "- Ensemble mit anderen AnsÃ¤tzen\n",
      "\n",
      "âœ… BEREIT FÃœR KAGGLE-SUBMISSION!\n",
      "\n",
      "================================================================================\n",
      "Viel Erfolg beim Hackathon! ðŸš€\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
